#pragma once

/*** Mean and variance values for the model
 *
 * These values are part of normalizer.ckpt from speechbrain (pytorch) training.
 *
 * Thus they are model dependent and should be updated whenever the model is trained/adapted.
 *
 *
 * They represent mean, respectively variation upon output tokens (e.g. BPE's ruled by the number
 * of output neurons)
 *
 */


static float glob_mean[] = { -27.5841, -21.6064, -15.2981, -15.6089,  -6.9220,  -8.7226,  -8.5894,
                             -7.7216,  -8.0884,  -7.6206,  -9.0038,  -9.3311,  -8.6084,  -7.5640,
                             -7.1085,  -7.3093,  -8.0213,  -9.0595,  -9.8999, -10.5225, -11.4679,
                             -12.7609, -14.1542, -15.3102, -16.2374, -17.0969, -16.8336, -18.0634,
                             -18.3719, -17.6867, -19.1672, -18.6864, -19.8328, -19.8385, -20.9386,
                             -21.1027, -21.7560, -22.2472, -22.7902, -23.3527, -23.7475, -23.9861,
                             -23.9714, -23.6511, -23.1698, -22.7106, -22.0562, -22.0301, -21.7214,
                             -22.3936, -22.5899, -22.9805, -23.0060, -22.8075, -22.3283, -21.9953,
                             -21.9245, -22.2317, -22.9367, -23.7518, -24.6820, -25.2968, -25.9567,
                             -26.2465, -26.5736, -27.4005, -28.2889, -28.7274, -28.7426, -29.0850,
                             -29.5380, -29.5092, -29.3698, -29.4831, -30.0997, -31.0345, -32.2878,
                             -33.9360, -35.7207, -37.0819
};


static float glob_std[] = { 8.6262,  8.8795, 11.2686, 11.2590, 13.2540, 13.0044, 13.4918, 12.9829,
                            12.8881, 12.9859, 13.6733, 13.3399, 12.9062, 12.9290, 13.0168, 13.0816,
                            13.1260, 13.0215, 12.8102, 12.6349, 12.5177, 12.3377, 12.1611, 12.1174,
                            12.0765, 12.0484, 11.9042, 11.9631, 12.0200, 12.0857, 12.2288, 12.1515,
                            12.1403, 12.0766, 12.0034, 11.9510, 11.8840, 11.7419, 11.6179, 11.5609,
                            11.5489, 11.4958, 11.4423, 11.4452, 11.5377, 11.6829, 11.8055, 11.7848,
                            11.5999, 11.3866, 11.2231, 11.1542, 11.1079, 11.1480, 11.2170, 11.2562,
                            11.2577, 11.2619, 11.2132, 11.1324, 10.9928, 11.0858, 11.1969, 11.2660,
                            11.3559, 11.4148, 11.5156, 11.6411, 11.7388, 11.7535, 11.7706, 11.8060,
                            11.7567, 11.6937, 11.5448, 11.3622, 11.1381, 10.8710, 10.4397, 10.0138
};
